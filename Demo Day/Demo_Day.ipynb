{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get envirionment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, dotenv_values\n",
    "\n",
    "keys = list(dotenv_values(find_dotenv('.env')).items())\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY'] = keys[0][1]\n",
    "LANGCHAIN_API_KEY = os.environ['LANGCHAIN_API_KEY'] = keys[1][1]\n",
    "POLYGON_API_KEY = os.environ['POLYGON_API_KEY'] = keys[2][1]\n",
    "EMAIL = os.environ['EMAIL'] = keys[3][1] #make this a user entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_core langchain_openai langchain_community langsmith openai tiktoken cohere lxml polygon-api-client weasyprint html5lib pydyf CFFI tinycss2 cssselect2 Pyphen Pillow fontTools -qU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tools were ripped directly from the langchain source code to remove the requirement for current data from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Util that calls several of Polygon's stock market REST APIs.\n",
    "Docs: https://polygon.io/docs/stocks/getting-started\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import requests\n",
    "from langchain_core.pydantic_v1 import BaseModel, root_validator\n",
    "from langchain_core.utils import get_from_dict_or_env\n",
    "\n",
    "POLYGON_BASE_URL = \"https://api.polygon.io/\"\n",
    "\n",
    "class PolygonAPIWrapper(BaseModel):\n",
    "    \"\"\"Wrapper for Polygon API.\"\"\"\n",
    "\n",
    "    polygon_api_key: Optional[str] = None\n",
    "\n",
    "    @root_validator(pre=True)\n",
    "    def validate_environment(cls, values: Dict) -> Dict:\n",
    "        \"\"\"Validate that api key in environment.\"\"\"\n",
    "        polygon_api_key = get_from_dict_or_env(\n",
    "            values, \"polygon_api_key\", \"POLYGON_API_KEY\"\n",
    "        )\n",
    "        values[\"polygon_api_key\"] = polygon_api_key\n",
    "\n",
    "        return values\n",
    "\n",
    "    def get_financials(self, ticker: str) -> Optional[dict]:\n",
    "        \"\"\"\n",
    "        Get fundamental financial data, which is found in balance sheets,\n",
    "        income statements, and cash flow statements for a given ticker.\n",
    "\n",
    "        /vX/reference/financials\n",
    "        \"\"\"\n",
    "        url = (\n",
    "            f\"{POLYGON_BASE_URL}vX/reference/financials?\"\n",
    "            f\"ticker={ticker}&\"\n",
    "            f\"apiKey={self.polygon_api_key}\"\n",
    "        )\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        status = data.get(\"status\", None)\n",
    "        if status != \"OK\":\n",
    "            raise ValueError(f\"API Error: {data}\")\n",
    "\n",
    "        return data.get(\"results\", None)\n",
    "\n",
    "    def get_last_quote(self, ticker: str) -> Optional[dict]:\n",
    "        \"\"\"\n",
    "        Get the most recent National Best Bid and Offer (Quote) for a ticker.\n",
    "\n",
    "        /v2/last/nbbo/{ticker}\n",
    "        \"\"\"\n",
    "        url = f\"{POLYGON_BASE_URL}v2/last/nbbo/{ticker}?apiKey={self.polygon_api_key}\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        status = data.get(\"status\", None)\n",
    "        if status != \"OK\":\n",
    "            raise ValueError(f\"API Error: {data}\")\n",
    "\n",
    "        return data.get(\"results\", None)\n",
    "\n",
    "    def get_ticker_news(self, ticker: str) -> Optional[dict]:\n",
    "        \"\"\"\n",
    "        Get the most recent news articles relating to a stock ticker symbol,\n",
    "        including a summary of the article and a link to the original source.\n",
    "\n",
    "        /v2/reference/news\n",
    "        \"\"\"\n",
    "        url = (\n",
    "            f\"{POLYGON_BASE_URL}v2/reference/news?\"\n",
    "            f\"ticker={ticker}&\"\n",
    "            f\"apiKey={self.polygon_api_key}\"\n",
    "        )\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        status = data.get(\"status\", None)\n",
    "        if status != \"OK\":\n",
    "            raise ValueError(f\"API Error: {data}\")\n",
    "\n",
    "        return data.get(\"results\", None)\n",
    "\n",
    "    def get_aggregates(self, ticker: str, **kwargs: Any) -> Optional[dict]:\n",
    "        \"\"\"\n",
    "        Get aggregate bars for a stock over a given date range\n",
    "        in custom time window sizes.\n",
    "\n",
    "        /v2/aggs/ticker/{ticker}/range/{multiplier}/{timespan}/{from_date}/{to_date}\n",
    "        \"\"\"\n",
    "        timespan = kwargs.get(\"timespan\", \"day\")\n",
    "        multiplier = kwargs.get(\"timespan_multiplier\", 1)\n",
    "        from_date = kwargs.get(\"from_date\", None)\n",
    "        to_date = kwargs.get(\"to_date\", None)\n",
    "        adjusted = kwargs.get(\"adjusted\", True)\n",
    "        sort = kwargs.get(\"sort\", \"asc\")\n",
    "\n",
    "        url = (\n",
    "            f\"{POLYGON_BASE_URL}v2/aggs\"\n",
    "            f\"/ticker/{ticker}\"\n",
    "            f\"/range/{multiplier}\"\n",
    "            f\"/{timespan}\"\n",
    "            f\"/{from_date}\"\n",
    "            f\"/{to_date}\"\n",
    "            f\"?apiKey={self.polygon_api_key}\"\n",
    "            f\"&adjusted={adjusted}\"\n",
    "            f\"&sort={sort}\"\n",
    "        )\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        status = data.get(\"status\", None)\n",
    "        if status != \"DELAYED\":\n",
    "            raise ValueError(f\"API Error: {data}\")\n",
    "\n",
    "        return data.get(\"results\", None)\n",
    "\n",
    "    def run(self, mode: str, ticker: str, **kwargs: Any) -> str:\n",
    "        if mode == \"get_financials\":\n",
    "            return json.dumps(self.get_financials(ticker))\n",
    "        elif mode == \"get_last_quote\":\n",
    "            return json.dumps(self.get_last_quote(ticker))\n",
    "        elif mode == \"get_ticker_news\":\n",
    "            return json.dumps(self.get_ticker_news(ticker))\n",
    "        elif mode == \"get_aggregates\":\n",
    "            return json.dumps(self.get_aggregates(ticker, **kwargs))\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid mode {mode} for Polygon API.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain_core.callbacks import CallbackManagerForToolRun\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "class PolygonAggregatesSchema(BaseModel):\n",
    "    \"\"\"Input for PolygonAggregates.\"\"\"\n",
    "\n",
    "    ticker: str = Field(\n",
    "        description=\"The ticker symbol to fetch aggregates for.\",\n",
    "    )\n",
    "    timespan: str = Field(\n",
    "        description=\"The size of the time window. \"\n",
    "        \"Possible values are: \"\n",
    "        \"second, minute, hour, day, week, month, quarter, year. \"\n",
    "        \"Default is 'day'\",\n",
    "    )\n",
    "    timespan_multiplier: int = Field(\n",
    "        description=\"The number of timespans to aggregate. \"\n",
    "        \"For example, if timespan is 'day' and \"\n",
    "        \"timespan_multiplier is 1, the result will be daily bars. \"\n",
    "        \"If timespan is 'day' and timespan_multiplier is 5, \"\n",
    "        \"the result will be weekly bars.  \"\n",
    "        \"Default is 1.\",\n",
    "    )\n",
    "    from_date: str = Field(\n",
    "        description=\"The start of the aggregate time window. \"\n",
    "        \"Either a date with the format YYYY-MM-DD or \"\n",
    "        \"a millisecond timestamp.\",\n",
    "    )\n",
    "    to_date: str = Field(\n",
    "        description=\"The end of the aggregate time window. \"\n",
    "        \"Either a date with the format YYYY-MM-DD or \"\n",
    "        \"a millisecond timestamp.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class PolygonAggregates(BaseTool):\n",
    "    \"\"\"\n",
    "    Tool that gets aggregate bars (stock prices) over a\n",
    "    given date range for a given ticker from Polygon.\n",
    "    \"\"\"\n",
    "\n",
    "    mode: str = \"get_aggregates\"\n",
    "    name: str = \"polygon_aggregates\"\n",
    "    description: str = (\n",
    "        \"A wrapper around Polygon's Aggregates API. \"\n",
    "        \"This tool is useful for fetching aggregate bars (stock prices) for a ticker. \"\n",
    "        \"Input should be the ticker, date range, timespan, and timespan multiplier\"\n",
    "        \" that you want to get the aggregate bars for.\"\n",
    "    )\n",
    "    args_schema: Type[PolygonAggregatesSchema] = PolygonAggregatesSchema\n",
    "\n",
    "    api_wrapper: PolygonAPIWrapper\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        ticker: str,\n",
    "        timespan: str,\n",
    "        timespan_multiplier: int,\n",
    "        from_date: str,\n",
    "        to_date: str,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the Polygon API tool.\"\"\"\n",
    "        return self.api_wrapper.run(\n",
    "            mode=self.mode,\n",
    "            ticker=ticker,\n",
    "            timespan=timespan,\n",
    "            timespan_multiplier=timespan_multiplier,\n",
    "            from_date=from_date,\n",
    "            to_date=to_date,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain_core.callbacks import CallbackManagerForToolRun\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "class Inputs(BaseModel):\n",
    "    \"\"\"Inputs for Polygon's Financials API\"\"\"\n",
    "\n",
    "    query: str\n",
    "\n",
    "\n",
    "class PolygonFinancials(BaseTool):\n",
    "    \"\"\"Tool that gets the financials of a ticker from Polygon\"\"\"\n",
    "\n",
    "    mode: str = \"get_financials\"\n",
    "    name: str = \"polygon_financials\"\n",
    "    description: str = (\n",
    "        \"A wrapper around Polygon's Stock Financials API. \"\n",
    "        \"This tool is useful for fetching fundamental financials from \"\n",
    "        \"balance sheets, income statements, and cash flow statements \"\n",
    "        \"for a stock ticker. The input should be the ticker that you want \"\n",
    "        \"to get the latest fundamental financial data for.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = Inputs\n",
    "\n",
    "    api_wrapper: PolygonAPIWrapper\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        query: str,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the Polygon API tool.\"\"\"\n",
    "        return self.api_wrapper.run(self.mode, ticker=query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain_core.callbacks import CallbackManagerForToolRun\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "class Inputs(BaseModel):\n",
    "    \"\"\"Inputs for Polygon's Ticker News API\"\"\"\n",
    "\n",
    "    query: str\n",
    "\n",
    "\n",
    "class PolygonTickerNews(BaseTool):\n",
    "    \"\"\"Tool that gets the latest news for a given ticker from Polygon\"\"\"\n",
    "\n",
    "    mode: str = \"get_ticker_news\"\n",
    "    name: str = \"polygon_ticker_news\"\n",
    "    description: str = (\n",
    "        \"A wrapper around Polygon's Ticker News API. \"\n",
    "        \"This tool is useful for fetching the latest news for a stock. \"\n",
    "        \"Input should be the ticker that you want to get the latest news for.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = Inputs\n",
    "\n",
    "    api_wrapper: PolygonAPIWrapper\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        query: str,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Use the Polygon API tool.\"\"\"\n",
    "        return self.api_wrapper.run(self.mode, ticker=query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\\n\\nif os.path.exists(\"./data/vectorstore\"):\\n    vectorstore = FAISS.load_local(\\n        \"./data/vectorstore\", \\n        embeddings, \\n        allow_dangerous_deserialization=True # this is necessary to load the vectorstore from disk as it\\'s stored as a `.pkl` file.\\n    )\\n    retriever = vectorstore.as_retriever()\\n    print(\"Loaded Vectorstore\")\\nelse:\\n    print(\"Indexing Files\")\\n    os.makedirs(\"./data/vectorstore\", exist_ok=True)\\n    for i in range(0, len(split_documents), 32):\\n        if i == 0:\\n            vectorstore = FAISS.from_documents(split_documents[i:i+32], embeddings)\\n            continue\\n        vectorstore.add_documents(split_documents[i:i+32])\\n    vectorstore.save_local(\"./data/vectorstore\")\\n\\n'"
      ]
     },
     "execution_count": 1364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "if os.path.exists(\"./data/vectorstore\"):\n",
    "    vectorstore = FAISS.load_local(\n",
    "        \"./data/vectorstore\", \n",
    "        embeddings, \n",
    "        allow_dangerous_deserialization=True # this is necessary to load the vectorstore from disk as it's stored as a `.pkl` file.\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    print(\"Loaded Vectorstore\")\n",
    "else:\n",
    "    print(\"Indexing Files\")\n",
    "    os.makedirs(\"./data/vectorstore\", exist_ok=True)\n",
    "    for i in range(0, len(split_documents), 32):\n",
    "        if i == 0:\n",
    "            vectorstore = FAISS.from_documents(split_documents[i:i+32], embeddings)\n",
    "            continue\n",
    "        vectorstore.add_documents(split_documents[i:i+32])\n",
    "    vectorstore.save_local(\"./data/vectorstore\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@tool\\ndef vectorize_data(url):\\n    This tool is used to embed html data into the locally cached vector database for Retrieval Augmented Generation. Any time a financial report is retrieved from the EDGAR database, the url should be passed to this function to ensure that the data is embedded and cached. '"
      ]
     },
     "execution_count": 1365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "import datetime\n",
    "import requests\n",
    "from weasyprint import HTML\n",
    "\n",
    "@tool\n",
    "def get_datetime() -> str:\n",
    "    \"\"\"Get the current date and time in YYYY-MM-DD HH:MM:SS format.\"\"\"\n",
    "    return str(datetime.datetime.now())\n",
    "\n",
    "@tool\n",
    "def get_date() -> str:\n",
    "    \"\"\"Get the current date in YYYY-MM-DD format. Also useful when determining the current quarter.\"\"\"\n",
    "    return str(datetime.datetime.now()).split(\" \")[0]\n",
    "\n",
    "@tool\n",
    "def get_time() -> str:\n",
    "    \"\"\"Get the current time in HH:MM:SS format.\"\"\"\n",
    "    return str(datetime.datetime.now()).split(\" \")[1]\n",
    "\n",
    "@tool\n",
    "def get_quarter(date:str) -> str:\n",
    "    \"\"\"This tool takes a date in YYYY-MM-DD format as an argument and returns the quarter and year in the format 'QQ YYYY'.\"\"\"\n",
    "    quarters = {\n",
    "        \"01\" : \"Q1\",\n",
    "        \"02\" : \"Q1\",\n",
    "        \"03\" : \"Q1\",\n",
    "        \"04\" : \"Q2\",\n",
    "        \"05\" : \"Q2\",\n",
    "        \"06\" : \"Q2\",\n",
    "        \"07\" : \"Q3\",\n",
    "        \"08\" : \"Q3\",\n",
    "        \"09\" : \"Q3\",\n",
    "        \"10\" : \"Q4\",\n",
    "        \"11\" : \"Q4\",\n",
    "        \"12\" : \"Q4\",\n",
    "    }\n",
    "    return quarters[date.split(\"-\")[1]] + f\" {date.split('-')[0]}\"\n",
    "\n",
    "@tool\n",
    "def get_CIK(ticker) -> str:\n",
    "    \"\"\"This tool takes a company stock ticker as an argument and returns the CIK number. This is used when trying to query the EDGAR database for financial statements.\"\"\"\n",
    "    if ticker is not None:\n",
    "        result = CIK_df[CIK_df[\"ticker\"] == ticker]\n",
    "        cik = result[\"cik\"]\n",
    "        return str(cik.item()).zfill(10)\n",
    "\n",
    "@tool\n",
    "def get_financial_report(cik, report_type, date=None):\n",
    "    \"\"\"This tool takes a company CIK number from the get_CIK tool, financial report type, and an optional date. \n",
    "    This information is used to retrieve requested document from the EDGAR database and save it to a path that can be returned to the user. \n",
    "    If a date is provided, it must be in YYYY-MM-DD format.\"\"\"\n",
    "\n",
    "    url = f\"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
    "    header = {\n",
    "        \"User-Agent\" : EMAIL\n",
    "    }\n",
    "    company_filings = requests.get(url, headers=header).json()\n",
    "    company_filings_df = pd.DataFrame(company_filings[\"filings\"][\"recent\"])\n",
    "    company_filings_df = company_filings_df[company_filings_df.form == report_type]\n",
    "    \n",
    "    if date:\n",
    "        filing_dates = company_filings_df[\"filingDate\"].values\n",
    "        nearest_filing_date = get_nearest_filing_dates(date, filing_dates)\n",
    "        company_filings_df = company_filings_df[company_filings_df.filingDate == nearest_filing_date]\n",
    "        access_number = company_filings_df.accessionNumber.values[0].replace(\"-\", \"\")\n",
    "        file_name = company_filings_df.primaryDocument.values[0]\n",
    "        url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{access_number}/{file_name}\"\n",
    "        # dowloading and saving requested document to working directory\n",
    "        req_content = requests.get(url, headers=header).content.decode(\"utf-8\")\n",
    "        pdf_path = f'./data/{file_name}'+\".pdf\"\n",
    "        HTML(string=req_content, base_url=\"\").write_pdf(pdf_path)\n",
    "        return pdf_path\n",
    "\n",
    "    else:\n",
    "        access_number = company_filings_df.accessionNumber.values[0].replace(\"-\", \"\")\n",
    "        file_name = company_filings_df.primaryDocument.values[0]\n",
    "        url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{access_number}/{file_name}\"\n",
    "        # dowloading and saving requested document to working directory\n",
    "        req_content = requests.get(url, headers=header).content.decode(\"utf-8\")\n",
    "        pdf_path = f'./data/{file_name}'+\".pdf\"\n",
    "        HTML(string=req_content, base_url=\"\").write_pdf(pdf_path)\n",
    "        return pdf_path\n",
    "\n",
    "def get_nearest_filing_dates(date, filing_dates):\n",
    "    \"\"\"This tool takes a date in YYYY-MM-DD format as arguments. It should be called \n",
    "    The tool is used to find the filing date closest to the user requested filing date. The user should be told what filing \n",
    "    data is the closest match to their query.\"\"\"\n",
    "\n",
    "    sums = []\n",
    "    for filing_date in filing_dates:\n",
    "        filing_date_year, filing_date_month, filing_date_day = filing_date.split(\"-\")[0], filing_date.split(\"-\")[1], filing_date.split(\"-\")[2]\n",
    "        date_year, date_month, date_day = date.split(\"-\")[0], date.split(\"-\")[1], date.split(\"-\")[2]\n",
    "        #Weighted sum of the difference of each component part. The year should take priority over the month and the month should take priority over the day.\n",
    "        sum = abs(int(date_year)-int(filing_date_year))*0.5 + abs(int(date_month)-int(filing_date_month))*0.3 + abs(int(date_day)-int(filing_date_day))*0.2\n",
    "        sums.append(sum)\n",
    "    m = min(sums)\n",
    "    idx = sums.index(m)\n",
    "    return filing_dates[idx]\n",
    "\n",
    "\"\"\"\n",
    "@tool\n",
    "def vectorize_data(url):\n",
    "    This tool is used to embed html data into the locally cached vector database for Retrieval Augmented Generation. Any time a financial report is retrieved from the EDGAR database, the url should be passed to this function to ensure that the data is embedded and cached. \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get JSON CIK data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "#Reference found here: https://www.kaggle.com/code/svendaj/extracting-data-from-sec-edgar-restful-apis\n",
    "\n",
    "with open(\"./data/company_tickers_exchange.json\", \"r\") as f:\n",
    "    CIK_dict = json.load(f)\n",
    "\n",
    "CIK_df = pd.DataFrame(CIK_dict[\"data\"], columns=CIK_dict[\"fields\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up tool belt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.ddg_search import DuckDuckGoSearchRun\n",
    "\n",
    "api_wrapper = PolygonAPIWrapper(polygon_api_key=POLYGON_API_KEY)\n",
    "\n",
    "tool_belt = [\n",
    "    get_datetime,\n",
    "    get_date,\n",
    "    get_time,\n",
    "    get_quarter,\n",
    "    get_CIK,\n",
    "    get_financial_report,\n",
    "    DuckDuckGoSearchRun(),\n",
    "    PolygonAggregates(api_wrapper=api_wrapper),\n",
    "    PolygonFinancials(api_wrapper=api_wrapper),\n",
    "    PolygonTickerNews(api_wrapper=api_wrapper),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up tool executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "tool_executor = ToolExecutor(tool_belt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1369,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "functions = [convert_to_openai_function(t) for t in tool_belt]\n",
    "model = model.bind_functions(functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up agent state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "  messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolInvocation\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage\n",
    "\n",
    "def call_model(state):\n",
    "  messages = state[\"messages\"]\n",
    "  response = model.invoke(messages)\n",
    "  return {\"messages\" : [response]}\n",
    "\n",
    "def call_tool(state):\n",
    "  last_message = state[\"messages\"][-1]\n",
    "\n",
    "  action = ToolInvocation(\n",
    "      tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "      tool_input=json.loads(\n",
    "          last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "      )\n",
    "  )\n",
    "\n",
    "  response = tool_executor.invoke(action)\n",
    "\n",
    "  function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "\n",
    "  return {\"messages\" : [function_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1373,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", call_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1374,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.set_entry_point(\"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "  last_message = state[\"messages\"][-1]\n",
    "\n",
    "  if \"function_call\" not in last_message.additional_kwargs:\n",
    "    return \"end\"\n",
    "\n",
    "  return \"continue\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\" : \"action\",\n",
    "        \"end\" : END\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_edge(\"action\", \"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_messages(messages):\n",
    "  next_is_tool = False\n",
    "  initial_query = True\n",
    "  for message in messages[\"messages\"]:\n",
    "    if \"function_call\" in message.additional_kwargs:\n",
    "      print()\n",
    "      print(f'Tool Call - Name: {message.additional_kwargs[\"function_call\"][\"name\"]} + Query: {message.additional_kwargs[\"function_call\"][\"arguments\"]}')\n",
    "      next_is_tool = True\n",
    "      continue\n",
    "    if next_is_tool:\n",
    "      print(f\"Tool Response: {message.content}\")\n",
    "      next_is_tool = False\n",
    "      continue\n",
    "    if initial_query:\n",
    "      print(f\"Initial Query: {message.content}\")\n",
    "      print()\n",
    "      initial_query = False\n",
    "      continue\n",
    "    print()\n",
    "    print(f\"Agent Response: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Query: Can you retreive Nvidia's 10-Q filings for April 1st, 2021?\n",
      "\n",
      "\n",
      "Tool Call - Name: get_CIK + Query: {\"ticker\":\"NVDA\"}\n",
      "Tool Response: 0001045810\n",
      "\n",
      "Tool Call - Name: get_financial_report + Query: {\"cik\":\"0001045810\",\"report_type\":\"10-Q\",\"date\":\"2021-04-01\"}\n",
      "Tool Response: ./data/nvda2020q110q.htm.pdf\n",
      "\n",
      "Agent Response: I have retrieved Nvidia's 10-Q filing for April 1st, 2021. You can download it using the link below:\n",
      "\n",
      "[Nvidia 10-Q Filing - April 1st, 2021](sandbox:/data/nvda2020q110q.htm.pdf)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\" : [HumanMessage(content=\"Can you retreive Nvidia's 10-Q filings for April 1st, 2021?\")]}\n",
    "\n",
    "messages = app.invoke(inputs)\n",
    "\n",
    "print_messages(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
